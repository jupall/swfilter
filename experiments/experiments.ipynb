{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append('../src')\n",
    "\n",
    "from swfilter import sw_outlier_detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn as sk\n",
    "from scipy.io import arff\n",
    "import mlflow\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, run this from terminal :\n",
    "\n",
    "mlflow server --host 127.0.0.1 --port 8081"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment_id: 791358303679491057\n",
      "Artifact Location: mlflow-artifacts:/791358303679491057\n",
      "Name: swfilter_test\n",
      "Tags: {}\n",
      "Lifecycle_stage: active\n"
     ]
    }
   ],
   "source": [
    "mlflow.set_tracking_uri(uri=\"http://127.0.0.1:8081\")\n",
    "# Create a new MLflow Experiment\n",
    "experiment_id = \"swfilter_test\"\n",
    "experiment = mlflow.set_experiment(experiment_id)\n",
    "\n",
    "# Get Experiment Details\n",
    "print(\"Experiment_id: {}\".format(experiment.experiment_id))\n",
    "print(\"Artifact Location: {}\".format(experiment.artifact_location))\n",
    "print(\"Name: {}\".format(experiment.name))\n",
    "print(\"Tags: {}\".format(experiment.tags))\n",
    "print(\"Lifecycle_stage: {}\".format(experiment.lifecycle_stage))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_dataset(folder_name:str, dataset_name:str)->pd.DataFrame:\n",
    "    arff_file = arff.loadarff(f'../datasets/{folder_name}/{dataset_name}.arff')\n",
    "    df_file = pd.DataFrame(arff_file[0])\n",
    "    features = df_file.drop(columns=['outlier', 'id'])\n",
    "    label = df_file['outlier']\n",
    "    return features, label, df_file\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1, -1,  1, -1,  1, -1,  1, -1,  1, -1,  1, -1,  1, -1,  1, -1,  1,\n",
       "       -1,  1, -1,  1, -1,  1, -1,  1, -1,  1, -1,  1, -1,  1, -1,  1, -1,\n",
       "        1, -1,  1, -1,  1, -1,  1, -1,  1, -1,  1, -1,  1, -1,  1, -1,  1,\n",
       "       -1,  1, -1,  1, -1,  1, -1,  1, -1,  1, -1,  1, -1,  1, -1,  1, -1,\n",
       "        1, -1,  1, -1,  1, -1,  1, -1,  1, -1,  1, -1,  1, -1,  1, -1,  1,\n",
       "       -1,  1, -1,  1, -1,  1, -1,  1, -1,  1, -1,  1,  1, -1,  1, -1,  1,\n",
       "       -1,  1, -1,  1, -1,  1, -1,  1, -1,  1, -1,  1, -1,  1, -1,  1, -1,\n",
       "        1, -1,  1, -1,  1, -1,  1, -1,  1, -1,  1, -1,  1, -1,  1, -1,  1,\n",
       "       -1,  1, -1,  1, -1,  1, -1,  1, -1,  1, -1,  1, -1,  1, -1,  1, -1,\n",
       "        1, -1,  1, -1,  1, -1,  1, -1,  1, -1,  1, -1,  1, -1,  1, -1,  1,\n",
       "       -1,  1, -1,  1, -1,  1, -1,  1, -1,  1, -1,  1, -1,  1, -1,  1, -1,\n",
       "        1, -1,  1, -1,  1, -1,  1, -1,  1, -1,  1, -1,  1, -1,  1, -1,  1,\n",
       "       -1,  1, -1,  1, -1,  1, -1,  1, -1,  1, -1,  1, -1,  1, -1,  1, -1,\n",
       "        1, -1,  1, -1,  1, -1,  1, -1,  1, -1,  1, -1,  1, -1,  1, -1,  1,\n",
       "       -1,  1, -1,  1, -1,  1, -1,  1, -1,  1, -1,  1, -1,  1, -1,  1,  1,\n",
       "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#features, label, data = import_dataset('Lymphography', 'Lymphography_withoutdupl_norm_idf')\n",
    "dataset_name = 'Ionosphere'\n",
    "dataset_precise_name = 'Ionosphere_withoutdupl_norm'\n",
    "features, label, data = import_dataset(dataset_name, dataset_precise_name)\n",
    "X = features.values\n",
    "y = label.values == b'yes'\n",
    "y = np.where(y, -1, 1)\n",
    "display(y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparateurs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "\n",
    "# Local outlier factor\n",
    "n_neighbors = 20\n",
    "contamination = 0.1\n",
    "leaf_size = 30\n",
    "clf_lof = LocalOutlierFactor(n_neighbors=n_neighbors, contamination=contamination, algorithm='auto', n_jobs=-1, leaf_size=leaf_size)\n",
    "y_lof = clf_lof.fit_predict(X)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Isolation forest\n",
    "max_samples = 'auto'\n",
    "contamination = 'auto'\n",
    "max_features = X.shape[1]\n",
    "clf_forest = IsolationForest(max_samples=max_samples, contamination=contamination, max_features=max_features, random_state=42, n_jobs=-1)\n",
    "y_forest = clf_forest.fit_predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps = 0.01\n",
    "n = 30\n",
    "n_projections = 100\n",
    "p = 0.9\n",
    "# SW filter original\n",
    "y_swo = sw_outlier_detector(data = X, eps = eps, n = n, n_projections=n_projections, seed = 42, p = p, n_jobs=-1, swtype='original')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SW filter\n",
    "eps_spherical = 0.002\n",
    "y_sws = sw_outlier_detector(data = X, eps = eps_spherical, n = 3, n_projections=10, seed = 42,  p = p, n_jobs=-1, swtype='spherical')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = ['outlier_bool', 'lof', 'forest', 'swo', 'sws']\n",
    "data['lof'] = y_lof < 0\n",
    "data['forest'] = y_forest < 0\n",
    "data['swo'] = y_swo\n",
    "data['sws'] = y_sws\n",
    "data['outlier_bool'] = data['outlier'] == b'yes'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>outlier_bool</th>\n",
       "      <th>lof</th>\n",
       "      <th>forest</th>\n",
       "      <th>swo</th>\n",
       "      <th>sws</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>true_positives</th>\n",
       "      <td>126.0</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>17.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>false_positives</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>true_negatives</th>\n",
       "      <td>225.0</td>\n",
       "      <td>223.000000</td>\n",
       "      <td>203.000000</td>\n",
       "      <td>225.000000</td>\n",
       "      <td>225.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>false_negatives</th>\n",
       "      <td>0.0</td>\n",
       "      <td>93.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>126.000000</td>\n",
       "      <td>109.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.729345</td>\n",
       "      <td>0.794872</td>\n",
       "      <td>0.641026</td>\n",
       "      <td>0.689459</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 outlier_bool         lof      forest         swo         sws\n",
       "true_positives          126.0   33.000000   76.000000    0.000000   17.000000\n",
       "false_positives           0.0    2.000000   22.000000    0.000000    0.000000\n",
       "true_negatives          225.0  223.000000  203.000000  225.000000  225.000000\n",
       "false_negatives           0.0   93.000000   50.000000  126.000000  109.000000\n",
       "precision                 1.0    0.729345    0.794872    0.641026    0.689459"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dict_results = {}\n",
    "for model in models:\n",
    "    true_positives = (data.loc[(data['outlier_bool'] == True) & (data[model] == True)]).count()[0]\n",
    "    false_positives =(data.loc[(data['outlier_bool'] == False) & (data[model] == True)]).count()[0]\n",
    "    true_negatives = (data.loc[(data['outlier_bool'] == False) & (data[model] == False)]).count()[0]\n",
    "    false_negatives = (data.loc[(data['outlier_bool'] == True) & (data[model] == False)]).count()[0]\n",
    "    precision = (true_positives + true_negatives) / (true_positives + true_negatives + false_positives + false_negatives)\n",
    "    dict_results[model] = {'true_positives': true_positives, 'false_positives': false_positives, 'true_negatives': true_negatives, 'false_negatives': false_negatives, 'precision': precision}\n",
    "    \n",
    "\n",
    "df_results = pd.DataFrame(dict_results)\n",
    "\n",
    "display(df_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## hyperopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import hp, fmin, tpe, Trials, STATUS_OK\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.metrics import precision_score, make_scorer\n",
    "from functools import partial\n",
    "import mlflow\n",
    "\n",
    "# Define search spaces\n",
    "space_lof = {\n",
    "    'n_neighbors': hp.quniform('n_neighbors', 5, 50,1),\n",
    "    'algorithm': hp.choice('algorithm', ['auto', 'ball_tree', 'kd_tree', 'brute']),\n",
    "    'leaf_size': hp.quniform('leaf_size', 5, 50, 1),\n",
    "    'metric': hp.choice('metric', ['euclidean', 'manhattan', 'chebyshev', 'minkowski'])\n",
    "}\n",
    "\n",
    "space_forest = {\n",
    "    'n_estimators': hp.quniform('n_estimators', 100, 200, 1),\n",
    "    'max_samples': hp.quniform('max_samples', 1, X.shape[1],1),\n",
    "    'contamination': hp.loguniform('contamination', -7, -0.70),\n",
    "    'max_features': hp.quniform('max_features', 1, 10, 1)\n",
    "}\n",
    "\n",
    "\n",
    "# Adjusting the objective functions to include cross-validation on training data and evaluation on testing data\n",
    "\n",
    "def objective_lof(space, X_train, Y_train, X_test, Y_test, scoring, experiment_id, dataset_name):\n",
    "    mlflow.set_experiment(experiment_id)\n",
    "    with mlflow.start_run():\n",
    "        n_neighbors = int(space['n_neighbors'])\n",
    "        algorithm = space['algorithm']\n",
    "        leaf_size = int(space['leaf_size'])\n",
    "        metric = space['metric']\n",
    "        \n",
    "        model = LocalOutlierFactor(\n",
    "            n_neighbors=n_neighbors,\n",
    "            algorithm=algorithm,\n",
    "            leaf_size=leaf_size,\n",
    "            metric=metric,\n",
    "            novelty=True\n",
    "        )\n",
    "        \n",
    "        # Cross-validation on training data\n",
    "        cv_score = cross_val_score(model, X_train, Y_train, cv=5, scoring=scoring).mean()\n",
    "        \n",
    "        # Fit the model on the entire training dataset\n",
    "        model.fit(X_train)\n",
    "        \n",
    "        # Evaluate on the testing data\n",
    "        Y_pred = model.predict(X_test)\n",
    "        test_score = scoring(model, X_test, Y_test)\n",
    "        \n",
    "        # Log parameters, cross-validation score, and testing score\n",
    "        mlflow.log_param(\"n_neighbors\", n_neighbors)\n",
    "        mlflow.log_param(\"algorithm\", algorithm)\n",
    "        mlflow.log_param(\"leaf_size\", leaf_size)\n",
    "        mlflow.log_param(\"metric\", metric)\n",
    "        mlflow.log_param(\"dataset_name\", dataset_name)\n",
    "        mlflow.log_metric(\"cv_score\", cv_score)\n",
    "        mlflow.log_metric(\"test_score\", test_score)\n",
    "        mlflow.set_tag(\"model\", \"LocalOutlierFactor\")\n",
    "        \n",
    "        return {'loss': -cv_score, 'status': STATUS_OK}\n",
    "\n",
    "def objective_forest(space, X_train, Y_train, X_test, Y_test, scoring, experiment_id, dataset_name):\n",
    "    mlflow.set_experiment(experiment_id)\n",
    "    with mlflow.start_run():\n",
    "        n_estimators = int(space['n_estimators'])\n",
    "        max_samples = int(space['max_samples'])\n",
    "        contamination = space['contamination']\n",
    "        max_features = int(space['max_features'])\n",
    "        \n",
    "        model = IsolationForest(\n",
    "            n_estimators=n_estimators,\n",
    "            max_samples=max_samples,\n",
    "            contamination=contamination,\n",
    "            max_features=max_features,\n",
    "            random_state=42\n",
    "        )\n",
    "        \n",
    "        # Cross-validation on training data\n",
    "        cv_score = cross_val_score(model, X_train, Y_train, cv=5, scoring=scoring).mean()\n",
    "        \n",
    "        # Fit the model on the entire training dataset\n",
    "        model.fit(X_train)\n",
    "        \n",
    "        # Evaluate on the testing data\n",
    "        Y_pred = model.predict(X_test)\n",
    "        test_score = scoring(model, X_test, Y_test)\n",
    "        \n",
    "        # Log parameters, cross-validation score, and testing score\n",
    "        mlflow.log_param(\"n_estimators\", n_estimators)\n",
    "        mlflow.log_param(\"max_samples\", max_samples)\n",
    "        mlflow.log_param(\"contamination\", contamination)\n",
    "        mlflow.log_param(\"max_features\", max_features)\n",
    "        mlflow.log_param(\"dataset_name\", dataset_name)\n",
    "        mlflow.log_metric(\"cv_score\", cv_score)\n",
    "        mlflow.log_metric(\"test_score\", test_score)\n",
    "        mlflow.set_tag(\"model\", \"IsolationForest\")\n",
    "        \n",
    "        return {'loss': -cv_score, 'status': STATUS_OK}\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = sk.model_selection.train_test_split(X, y, test_size=0.4, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:01<00:00, 10.12trial/s, best loss: -0.9275252877793712]\n",
      "100%|██████████| 20/20 [00:13<00:00,  1.50trial/s, best loss: -0.7999245852187029]\n"
     ]
    }
   ],
   "source": [
    "# Example of using partial to create a function with pre-filled parameters\n",
    "# Create a precision scorer object\n",
    "scoring = make_scorer(precision_score, zero_division=0)\n",
    "objective_lof_partial = partial(objective_lof, X_train=X_train, Y_train=Y_train, X_test=X_test, Y_test=Y_test, scoring=scoring, experiment_id=experiment_id, dataset_name=dataset_name)\n",
    "objective_forest_partial = partial(objective_forest, X_train=X_train, Y_train=Y_train, X_test=X_test, Y_test=Y_test, scoring=scoring, experiment_id=experiment_id, dataset_name=dataset_name)\n",
    "max_evals = 20\n",
    "# Example of running a trial for LOF with the partial function\n",
    "trials_lof = Trials()\n",
    "best_lof = fmin(fn=objective_lof_partial,\n",
    "                space=space_lof,\n",
    "                algo=tpe.suggest,\n",
    "                max_evals=max_evals,\n",
    "                trials=trials_lof)\n",
    "\n",
    "# Example of running a trial for Isolation Forest with the partial function\n",
    "trials_iforest = Trials()\n",
    "best_iforest = fmin(fn=objective_forest_partial,\n",
    "                    space=space_forest,\n",
    "                    algo=tpe.suggest,\n",
    "                    max_evals=max_evals,\n",
    "                    trials=trials_iforest)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
