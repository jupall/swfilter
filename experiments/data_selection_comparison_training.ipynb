{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hyperopt as hp\n",
    "import numpy as np\n",
    "import scipy as sc\n",
    "\n",
    "\n",
    "import uci_datasets as uci\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import sklearn as sk\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import mlflow\n",
    "from hyperopt import fmin, tpe, hp, SparkTrials, STATUS_OK, Trials\n",
    "from datetime import datetime\n",
    "import torch.nn as nn\n",
    "import cvxpy as cp\n",
    "import mlflow.pytorch\n",
    "from mlflow.models.signature import infer_signature, set_signature\n",
    "import hyperopt\n",
    "from functools import partial\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from wadiroscnn import scnn\n",
    "import bench_data_selection as bench\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "choice_space = False\n",
    "if choice_space:\n",
    "    space_lof = {\n",
    "            'n_neighbors': hp.choice('n_neighbors', [5,10,20,30,40,50,60,70,80,90,100]),\n",
    "            'algorithm': hp.choice('algorithm', ['auto', 'ball_tree', 'kd_tree', 'brute']),\n",
    "            'leaf_size': hp.choice('leaf_size',[ 5, 10, 20,30, 40, 50, 60, 70, 80, 90, 100]),\n",
    "            'metric': hp.choice('metric', ['euclidean', 'manhattan'])\n",
    "        }\n",
    "\n",
    "    \n",
    "\n",
    "    space_sw = {\n",
    "            'eps': hp.choice('eps', [-7, -6, -5, -4, -3, -2, -1, 0, 1, 2, 3, 4]),\n",
    "            'n': hp.choice('n', [5, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100]),\n",
    "            'n_projections': hp.choice('n_projections', [50, 60, 70, 80, 90, 100, 110, 120, 130, 140, 150, 160, 170, 180, 190, 200]),\n",
    "            'p' : hp.choice('p', [0.6, 0.7, 0.8, 0.9, 0.95])\n",
    "        }\n",
    "\n",
    "    space_sw_smartsplit = space_sw | {\n",
    "            'n_clusters' : hp.choice('n_clusters', [2, 3, 4, 5, 6, 7, 8, 9, 10]),\n",
    "            'n_splits' : hp.choice('n_splits', [2, 3, 4, 5, 6, 7, 8, 9, 10, 15, 20, 25, 30])\n",
    "        }\n",
    "\n",
    "\n",
    "    space_fast_euclidian = {\n",
    "            'eps': hp.choice('eps', [-7, -6, -5, -4, -3, -2, -1, 0, 1, 2, 3, 4]),\n",
    "            'n': hp.choice('n', [5, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100]),\n",
    "            'p': hp.choice('p', [0.6, 0.7, 0.8, 0.9, 0.95])\n",
    "        }\n",
    "else:\n",
    "    space_lof = {\n",
    "            'n_neighbors': hp.quniform('n_neighbors', 5, 300, 1),\n",
    "            'algorithm': hp.choice('algorithm', ['auto', 'ball_tree', 'kd_tree', 'brute']),\n",
    "            'leaf_size': hp.quniform('leaf_size', 5, 300, 1),\n",
    "            'metric': hp.choice('metric', ['euclidean', 'manhattan'])\n",
    "        }\n",
    "    \n",
    "    space_sw = {\n",
    "            'eps': hp.loguniform('eps', -12, 1),\n",
    "            'n': hp.choice('n', [150, 300]),\n",
    "            'n_projections': hp.choice('n_projections', [40]),\n",
    "            'p' : hp.choice('p', [0.7, 0.8, 0.9])\n",
    "        }\n",
    "    \n",
    "    space_sw_smartsplit = space_sw | {\n",
    "            'n_clusters' : hp.choice('n_clusters', [3,4]),\n",
    "            'n_splits' : hp.choice('n_splits', [3,4])\n",
    "        }\n",
    "    \n",
    "    space_fast_euclidian = {\n",
    "            'eps': hp.loguniform('eps', -12, 7),\n",
    "            'n': hp.choice('n', [150, 300]),\n",
    "            'p' : hp.choice('p', [0.7, 0.8, 0.9])\n",
    "        }\n",
    "    \n",
    "    space_forest = {\n",
    "            'n_estimators': hp.quniform('n_estimators', 5, 300, 1),\n",
    "            'max_samples': hp.uniform('max_samples', 0.000001, 1.0),\n",
    "            'contamination': hp.loguniform('contamination', -7, -0.7),\n",
    "            'max_features': hp.uniform('max_features', 0.00001, 1.0)\n",
    "        }\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "space_scnn = {'max_neurons': hp.choice('max_neurons', [25])}# #20, 50, 100, 200, 300, 500])}\n",
    "                \n",
    "space_scnn_sw =  space_scnn | space_sw\n",
    "\n",
    "space_scnn_sw_smartsplit =  space_scnn | space_sw_smartsplit\n",
    "\n",
    "space_scnn_fast_euclidian =  space_scnn | space_fast_euclidian\n",
    "\n",
    "space_scnn_forest = space_scnn | space_forest\n",
    "\n",
    "space_scnn_lof = space_scnn | space_lof"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, run this from terminal :\n",
    "\n",
    "mlflow server --host 127.0.0.1 --port 8080"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_tracking_uri(uri=\"http://127.0.0.1:8080\")\n",
    "# Create a new MLflow Experiment\n",
    "experiment = mlflow.set_experiment(\"COMPARISON_DATA_SELECTION_100runs_split_2_noise_V3\")\n",
    "\n",
    "# Get Experiment Details\n",
    "print(\"Experiment_id: {}\".format(experiment.experiment_id))\n",
    "print(\"Artifact Location: {}\".format(experiment.artifact_location))\n",
    "print(\"Name: {}\".format(experiment.name))\n",
    "print(\"Tags: {}\".format(experiment.tags))\n",
    "print(\"Lifecycle_stage: {}\".format(experiment.lifecycle_stage))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_LIST = [ \n",
    "       'stock',\n",
    "\t'concrete',\n",
    "       'energy',\n",
    "       'solar', \n",
    "       'forest', \n",
    "       'wine',  #'airfoil', # 'energy', 'forest',\n",
    "\t]\n",
    "\n",
    "ALGORITHM_LIST = ['none',\n",
    "                  'fast_euclidian', \n",
    "                  'lof', \n",
    "                  'forest', \n",
    "                  'sw_smartsplit', \n",
    "                  ]\n",
    "\n",
    "\n",
    "solver_name = 'CLARABEL'\n",
    "verbose = False\n",
    "MAX = 100\n",
    "NOISE_VAR_X = 0.05\n",
    "NOISE_VAR_Y = 0.05\n",
    "\n",
    "splits = [5]\n",
    "\n",
    "print(splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i in splits:\n",
    "    for dataset_name in DATASET_LIST:\n",
    "        for selection_algorithm in ALGORITHM_LIST:\n",
    "            rng = np.random.default_rng(i)\n",
    "            # import data\n",
    "            uci_data = uci.Dataset(dataset_name)\n",
    "            X_train, Y_train, X_test, Y_test = uci_data.get_split(split = int(i))\n",
    "            \n",
    "\n",
    "            X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size=0.3, random_state=42)\n",
    "\n",
    "            scaler_x = StandardScaler()\n",
    "            scaler_y = StandardScaler()\n",
    "\n",
    "            # Fit and transform the features\n",
    "            X_train_scaled = scaler_x.fit_transform(X_train)\n",
    "            X_val_scaled = scaler_x.transform(X_val)\n",
    "            X_test_scaled = scaler_x.transform(X_test)\n",
    "\n",
    "            Y_train_scaled = scaler_y.fit_transform(Y_train)\n",
    "            Y_val_scaled = scaler_y.transform(Y_val)\n",
    "            Y_test_scaled = scaler_y.transform(Y_test)\n",
    "\n",
    "            X_train_scaled += rng.normal(0, NOISE_VAR_X, X_train_scaled.shape)\n",
    "            X_val_scaled += rng.normal(0, NOISE_VAR_X, X_val_scaled.shape)\n",
    "            Y_train_scaled += rng.normal(0, NOISE_VAR_Y, Y_train_scaled.shape)\n",
    "            Y_val_scaled += rng.normal(0, NOISE_VAR_Y, Y_val_scaled.shape)\n",
    "\n",
    "            data = {\"X_train\": X_train, \"Y_train\": Y_train,\"X_val\": X_val , \"Y_val\":Y_val,  \"X_test\": X_test, \"Y_test\": Y_test, \"X_train_scaled\": X_train_scaled, \"Y_train_scaled\": Y_train_scaled, \"X_val_scaled\": X_val_scaled ,\"Y_val_scaled\": Y_val_scaled ,\"X_test_scaled\": X_test_scaled, \"Y_test_scaled\": Y_test_scaled, 'scaler_y': scaler_y, 'scaler_x': scaler_x}\n",
    "\n",
    "            if selection_algorithm == 'lof':\n",
    "                search_space = space_scnn_lof\n",
    "                max_evals = MAX\n",
    "            elif selection_algorithm == 'sw':\n",
    "                search_space = space_scnn_sw\n",
    "                max_evals = MAX\n",
    "            elif selection_algorithm == 'sw_smartsplit':\n",
    "                search_space = space_scnn_sw_smartsplit\n",
    "                max_evals = MAX\n",
    "            elif selection_algorithm == 'fast_euclidian':\n",
    "                search_space = space_scnn_fast_euclidian\n",
    "                max_evals = MAX\n",
    "            elif selection_algorithm == 'forest':\n",
    "                search_space = space_scnn_forest\n",
    "                max_evals = MAX\n",
    "            elif selection_algorithm == 'none':\n",
    "                max_evals = 2\n",
    "                search_space = space_scnn\n",
    "            else:\n",
    "                raise ValueError(\"Unknown selection algorithm\")\n",
    "            \n",
    "            print(f\"SCNN on {dataset_name} with {selection_algorithm}: \\n\")\n",
    "            fmin_scnn = partial(bench.objective_scnn, data = data, solver_name=solver_name, experiment=experiment, dataset_name=dataset_name, verbose=verbose, selection_algorithm=selection_algorithm, split = i)\n",
    "            argmin = fmin(fn=fmin_scnn,\n",
    "                    space=search_space,\n",
    "                    algo= hyperopt.tpe.suggest, #partial(bench.suggest, nbMaxSucessiveFailures=1000), #hyperopt.tpe.suggest, # try anneal.suggest\n",
    "                    max_evals=max_evals) #trials=spark_trials)\n",
    "            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hyperopt as hp\n",
    "import numpy as np\n",
    "import scipy as sc\n",
    "\n",
    "\n",
    "import uci_datasets as uci\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import sklearn as sk\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import mlflow\n",
    "from hyperopt import fmin, tpe, hp, SparkTrials, STATUS_OK, Trials\n",
    "from datetime import datetime\n",
    "import torch.nn as nn\n",
    "import cvxpy as cp\n",
    "import mlflow.pytorch\n",
    "from mlflow.models.signature import infer_signature, set_signature\n",
    "import hyperopt\n",
    "from functools import partial\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from wadiroscnn import scnn\n",
    "import bench_data_selection as bench\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_tracking_uri(uri=\"http://127.0.0.1:8080\")\n",
    "experiment = mlflow.set_experiment(\"COMPARISON_DATA_SELECTION_100runs_split_2_noise_V3\")\n",
    "\n",
    "# Get Experiment Details\n",
    "print(\"Experiment_id: {}\".format(experiment.experiment_id))\n",
    "print(\"Artifact Location: {}\".format(experiment.artifact_location))\n",
    "print(\"Name: {}\".format(experiment.name))\n",
    "print(\"Tags: {}\".format(experiment.tags))\n",
    "print(\"Lifecycle_stage: {}\".format(experiment.lifecycle_stage))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = mlflow.search_runs([experiment.experiment_id],filter_string=\"status = 'FINISHED'\")\n",
    "#building_ids = df['params.building_id']\n",
    "\n",
    "datasets = df['params.dataset'].unique()\n",
    "print(datasets)\n",
    "#models = df['tags.model_name'].unique()\n",
    "models = ['scnn_and_fast_euclidian', 'scnn_and_sw_smartsplit', 'scnn_and_forest', 'scnn_and_lof',\n",
    "  'scnn_and_none']\n",
    "print(models)\n",
    "\n",
    "splits = df['params.split'].unique()\n",
    "print(splits)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "result_dict = {}\n",
    "mean_dict = {}\n",
    "\n",
    "for split in splits:\n",
    "    for dataset in datasets:\n",
    "        for model in models:\n",
    "            best_val= df.loc[(df['params.dataset'] == dataset) & (df['tags.model_name'] == model) & (df['params.split']==split)].sort_values(by=['metrics.MAE_val', 'end_time'], ascending=True).head(1)\n",
    "\n",
    "            #best_mse = df.loc[(df['params.benchmark_functions'] == function) & (df['tags.model_name'] == model)].sort_values(by='metrics.MSE_val', ascending=True).head(1)\n",
    "            #best_build = df.loc[ (df['tags.model_name'] == model)].sort_values(by='metrics.MAE_VAL_all_buildings_scaled', ascending=True).head(1)\n",
    "\n",
    "            if f'{dataset}' not in result_dict.keys():\n",
    "                result_dict[f'{dataset}'] = {}\n",
    "            if f'{model}' not in result_dict[f'{dataset}'].keys():\n",
    "                result_dict[f'{dataset}'][f'{model}'] = {}\n",
    "\n",
    "            #display(best_val)\n",
    "        \n",
    "            result_dict[f'{dataset}'][f'{model}'][f'{split}'] = {'MAE_test': best_val['metrics.MAE_test'].values[0], 'RMSE_test' : best_val['metrics.RMSE_test'].values[0], 'n_outliers': best_val['metrics.n_outliers'].values[0]}\n",
    "\n",
    "\n",
    "mean_dict = {}\n",
    "\n",
    "for dataset in result_dict.keys():\n",
    "    for model in result_dict[dataset].keys():\n",
    "        # Initialize the mean_dict structure for the current dataset and model\n",
    "        if dataset not in mean_dict:\n",
    "            mean_dict[dataset] = {}\n",
    "        if model not in mean_dict[dataset]:\n",
    "            mean_dict[dataset][model] = {}\n",
    "\n",
    "        # Calculate the mean for each metric across all splits\n",
    "        mean_dict[dataset][model] = {\n",
    "            'MAE_test': np.mean([result_dict[dataset][model][split]['MAE_test'] for split in result_dict[dataset][model].keys()]),\n",
    "            'RMSE_test': np.mean([result_dict[dataset][model][split]['RMSE_test'] for split in result_dict[dataset][model].keys()]),\n",
    "            'n_outliers': np.mean([result_dict[dataset][model][split]['n_outliers'] for split in result_dict[dataset][model].keys()])\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2 = pd.concat({\n",
    "        k: pd.DataFrame.from_dict(v, 'index') for k, v in mean_dict.items()\n",
    "    }, \n",
    "    axis=0)\n",
    "print(df_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_MAE = pd.DataFrame(columns=datasets, index=models)\n",
    "data_RMSE = pd.DataFrame(columns=datasets, index=models)\n",
    "data_outliers = pd.DataFrame(columns=datasets, index=models)\n",
    "\n",
    "for ids in datasets:\n",
    "        for model in models:\n",
    "                if ids in df_2['MAE_test'] and model and ids is not None:\n",
    "                        data_MAE[ids][model] = df_2['MAE_test'][ids][model]\n",
    "                        data_RMSE[ids][model] = df_2['RMSE_test'][ids][model]\n",
    "                        data_outliers[ids][model] = df_2['n_outliers'][ids][model]\n",
    "mapper = {'scnn_and_none' : 'None', 'scnn_and_forest':'Isolation Forest', 'scnn_and_lof':'Local Outlier Factor', 'scnn_and_fast_euclidian': 'Fast Euclidian', 'scnn_and_sw_smartsplit':'Sliced-Wasserstein Smart Split'}\n",
    "\n",
    "data_MAE.rename(mapper, axis=0, inplace=True)\n",
    "data_RMSE.rename(mapper, axis=0, inplace=True)\n",
    "data_outliers.rename(mapper, axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data_MAE\n",
    "# Normalize each column by its range\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 6), dpi = 400)\n",
    "#plt.tight_layout()\n",
    "cmap = sns.color_palette(\"viridis\", as_cmap=True)\n",
    "heatmap = sns.heatmap(data.astype(float), cmap=cmap, annot=True, fmt=\".4f\",cbar_kws={'label': 'Test Mean Absolute Error'})\n",
    "\n",
    "# Set the function names as the y-axis labels\n",
    "heatmap.set_yticklabels(heatmap.get_yticklabels(), rotation=0)\n",
    "\n",
    "# Set the function names as the x-axis labels and place them on top\n",
    "heatmap.set_xticklabels(data.columns, rotation=45)\n",
    "heatmap.xaxis.tick_top()\n",
    "\n",
    "#plt.title('Your caption here', y=-0.1)\n",
    "#plt.title('Normalized error metrics for different models and benchmark functions')\n",
    "plt.savefig('data_selection_MAE.pdf', bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "data = data_RMSE\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 6), dpi = 400)\n",
    "#plt.tight_layout()\n",
    "cmap = sns.color_palette(\"viridis\", as_cmap=True)\n",
    "heatmap = sns.heatmap(data.astype(float), cmap=cmap, annot=True, fmt=\".4f\",cbar_kws={'label': 'Test Root Mean Squared Error'})\n",
    "\n",
    "# Set the function names as the y-axis labels\n",
    "heatmap.set_yticklabels(heatmap.get_yticklabels(), rotation=0)\n",
    "\n",
    "# Set the function names as the x-axis labels and place them on top\n",
    "heatmap.set_xticklabels(data.columns, rotation=45)\n",
    "heatmap.xaxis.tick_top()\n",
    "\n",
    "#plt.title('Your caption here', y=-0.1)\n",
    "#plt.title('Normalized error metrics for different models and benchmark functions')\n",
    "plt.savefig('data_selection_RMSE.pdf', bbox_inches='tight', dpi=400)\n",
    "plt.show()\n",
    "\n",
    "data = data_outliers\n",
    "plt.figure(figsize=(10, 6), dpi = 400)\n",
    "#plt.tight_layout()\n",
    "cmap = sns.color_palette(\"viridis\", as_cmap=True)\n",
    "heatmap = sns.heatmap(data.astype(float), cmap=cmap, annot=True, fmt=\".1f\",cbar_kws={'label': 'Outliers Filtered in Training'})\n",
    "\n",
    "# Set the function names as the y-axis labels\n",
    "heatmap.set_yticklabels(heatmap.get_yticklabels(), rotation=0)\n",
    "\n",
    "# Set the function names as the x-axis labels and place them on top\n",
    "heatmap.set_xticklabels(data.columns, rotation=45)\n",
    "heatmap.xaxis.tick_top()\n",
    "\n",
    "#plt.title('Your caption here', y=-0.1)\n",
    "#plt.title('Normalized error metrics for different models and benchmark functions')\n",
    "plt.savefig('data_selection_outliers.pdf', bbox_inches='tight', dpi=400)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize each column by its range (0.0 is best, 1.0 is worst)\n",
    "data = data_MAE\n",
    "data = (data - data.min()) / (data.max() - data.min())\n",
    "\n",
    "plt.figure(figsize=(10, 6), dpi=400)\n",
    "cmap = sns.color_palette(\"viridis\", as_cmap=True)\n",
    "heatmap = sns.heatmap(data.astype(float), cmap=cmap, annot=True, fmt=\".4f\", cbar_kws={'label': 'Normalized Test Mean Absolute Error'})\n",
    "\n",
    "# Set the function names as the y-axis labels\n",
    "heatmap.set_yticklabels(heatmap.get_yticklabels(), rotation=0)\n",
    "\n",
    "# Set the function names as the x-axis labels and place them on top\n",
    "heatmap.set_xticklabels(data.columns, rotation=45)\n",
    "heatmap.xaxis.tick_top()\n",
    "\n",
    "plt.savefig('data_selection_MAE_normalized.pdf', bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Normalize each column by its range (0.0 is best, 1.0 is worst)\n",
    "data = data_RMSE\n",
    "data = (data - data.min()) / (data.max() - data.min())\n",
    "\n",
    "plt.figure(figsize=(10, 6), dpi=400)\n",
    "cmap = sns.color_palette(\"viridis\", as_cmap=True)\n",
    "heatmap = sns.heatmap(data.astype(float), cmap=cmap, annot=True, fmt=\".4f\", cbar_kws={'label': 'Normalized Test Root Mean Squared Error'})\n",
    "\n",
    "# Set the function names as the y-axis labels\n",
    "heatmap.set_yticklabels(heatmap.get_yticklabels(), rotation=0)\n",
    "\n",
    "# Set the function names as the x-axis labels and place them on top\n",
    "heatmap.set_xticklabels(data.columns, rotation=45)\n",
    "heatmap.xaxis.tick_top()\n",
    "\n",
    "plt.savefig('data_selection_RMSE_normalized.pdf', bbox_inches='tight', dpi=400)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
